\section{Related Work}\label{sec:relatedwork}
Highly automated vehicles are typically \emph{learning-enabled cyber physical systems} operating in an uncertain dynamic environment, where learning about the \emph{dynamic environment} is enabled through \emph{inaccurate sensors}. This renders an exact inference of the state of the environment infeasible, necessitating suitable representations of the \emph{uncertainty} in such an inference about the dynamic environment. Appropriate representations of uncertainty in the inference have been investigated a.o. within the paradigm of \emph{probabilistic robotics}~\cite{probrob}, particularly as applied to vehicle localization in urban environments~\cite{Thrun2007,Thrun2009,Thrun2010}. In these and related works such as~\cite{Perrolaz2014,moras2014}, the environment uncertainty is represented as \emph{probabilistic
beliefs}. Applications of learning components in high assurance systems has been addressed in~\cite{Schumann}. More recently, the challenge of assuring the autonomy of learning-enabled cyber physical systems has been considered in the works~\cite{SeshiaNFM17,SeshiaSadigh18a,SeshiaSasdigh18b,Corina18}. In particular, \cite{SeshiaNFM17} considers the problem of falsifying signal temporal logic specifications for learning-enabled cyber physical systems, with the technique demonstrated on a simplified model of an automatic emergency braking system with a perception component based on deep neural networks. ``Human-aware'' dynamic control of semi-autonomous vehicles is considered in ~\cite{SeshiaSadigh18a} for estimating (and possibly even changing) the (cognitive) internal state of the human in the loop based on the observed (human) responses, by means of optimal planning through inverse reinforcement learning. A synthesis-based approach, aiming to ensure the correctness of learning-enabled cyber physical systems by construction, starting from probabilistic temporal logic specifications, with applications to autonomous driving under perception uncertainty in adversarial  environments is presented in~\cite{SeshiaSasdigh18b}. Contract-based compositional reasoning of learning-enabled autonomous systems is considered in~\cite{Corina18}, where Deep Neural Networks constitute the learning components.  Markov Decision Processes form the operational basis of the models in~\cite{Topcu18} generated from reinforcement learning, where strategies conforming to probabilistic temporal logic specifications are synthesized with the aim of enabling the safe navigation of autonomous systems among humans. When viewing the humans in such a setting as \emph{random obstacles}, such safe navigation may be formulated in the operational framework of \emph{stochastic hybrid systems}~\cite{LygerosPrandiniSHS,FraenzleProcosSHS} as a \emph{stochastic reach avoid problem}~\cite{TomlinHSCC2011}, solved by synthesis of stochastic optimal control policies using techniques from dynamic programming. A theorem-proving based approach to guaranteeing safe navigation of robots under environment and sensor uncertainty is presented in~\cite{Mitsch17}. Safe navigation of cooperative driver assistance systems by verification against probabilistic temporal properties has been considered in~\cite{DammMSCS13}. Prediction (using Gaussian propagation)  of the trajectory of motion of an autonomous vehicle  interacting with other traffic agents under uncertainty in localization and control (based on a Linear-Quadratic Gaussian Framework) is considered in~\cite{XuDolanICRA2014}. The related theme of stochastic control of linear systems under Gaussian uncertainty in the environment and in the system's trajectory is addressed in the works~\cite{VitusTomlinCDC2012,VitusTomlinCDC2013}. 







